{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SeqNLP_Project1_Questions(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xT7MKZuMRaCg"
      },
      "source": [
        "# Sentiment Classification\n",
        "\n",
        "\n",
        "### Generate Word Embeddings and retrieve outputs of each layer with Keras based on Classification task\n",
        "\n",
        "Word embeddings are a type of word representation that allows words with similar meaning to have a similar representation.\n",
        "\n",
        "It is a distributed representation for text that is perhaps one of the key breakthroughs for the impressive performance of deep learning methods on challenging natural language processing problems.\n",
        "\n",
        "We willl use the imdb dataset to learn word embeddings as we train our dataset. This dataset contains 25,000 movie reviews from IMDB, labeled with sentiment (positive or negative). \n",
        "\n",
        "\n",
        "\n",
        "### Dataset\n",
        "\n",
        "`from keras.datasets import imdb`\n",
        "\n",
        "Dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative). Reviews have been preprocessed, and each review is encoded as a sequence of word indexes (integers). For convenience, the words are indexed by their frequency in the dataset, meaning the for that has index 1 is the most frequent word. Use the first 20 words from each review to speed up training, using a max vocab size of 10,000.\n",
        "\n",
        "As a convention, \"0\" does not stand for a specific word, but instead is used to encode any unknown word.\n",
        "\n",
        "\n",
        "### Aim\n",
        "\n",
        "1. Import test and train data  \n",
        "2. Import the labels ( train and test) \n",
        "3. Get the word index and then Create key value pair for word and word_id. (12.5 points)\n",
        "4. Build a Sequential Model using Keras for Sentiment Classification task. (10 points)\n",
        "5. Report the Accuracy of the model. (5 points)  \n",
        "6. Retrive the output of each layer in keras for a given single test sample from the trained model you built. (2.5 points)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wq4RCyyPSYRp"
      },
      "source": [
        "#### Usage:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKgFGM6p9Dty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6cFTcSmsLhI",
        "colab_type": "code",
        "outputId": "755bf337-bc39-44c9-ea4f-0d8bd2d7865c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUTpn5O_vkZF",
        "colab_type": "code",
        "outputId": "a2008b5e-b43d-4942-cb3e-60b3a511d350",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "#Importing Libraries\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, GRU, Embedding,LSTM\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGCtiXUhSWss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "eb273324-28b1-456a-c416-4a8ddf522932"
      },
      "source": [
        "from keras.datasets import imdb\n",
        "\n",
        "vocab_size = 10000 #vocab size\n",
        "\n",
        "# vocab_size is no.of words to consider from the dataset, ordering based on frequency.\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCPC_WN-eCyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "vocab_size = 10000 #vocab size\n",
        "maxlen = 300  #number of word used from each review"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0g381XzeCyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load dataset as a list of ints\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
        "#make all sequences of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test =  pad_sequences(x_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVOXqQW13yXq",
        "colab_type": "code",
        "outputId": "df39e02a-78d9-47c3-c321-da596a00afe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Make Word to ID dictionary\n",
        "INDEX_FROM=3   # word index offset\n",
        "word_to_id = imdb.get_word_index() #Get the word index\n",
        "word_to_id = {k:(v+INDEX_FROM) for k,v in word_to_id.items()}\n",
        "\n",
        "word_to_id[\"<PAD>\"] = 0\n",
        "\n",
        "word_to_id[\"<START>\"] = 1\n",
        "\n",
        "word_to_id[\"<UNK>\"] = 2\n",
        "\n",
        "# Make ID to Word dictionary\n",
        "id_to_word = {value:key for key,value in word_to_id.items()}"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 1s 1us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On-2I6WtNG18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "94e8e2e6-a3a5-4ef2-a05b-ca8a35e4ed48"
      },
      "source": [
        "id_to_word"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{34704: 'fawn',\n",
              " 52009: 'tsukino',\n",
              " 52010: 'nunnery',\n",
              " 16819: 'sonja',\n",
              " 63954: 'vani',\n",
              " 1411: 'woods',\n",
              " 16118: 'spiders',\n",
              " 2348: 'hanging',\n",
              " 2292: 'woody',\n",
              " 52011: 'trawling',\n",
              " 52012: \"hold's\",\n",
              " 11310: 'comically',\n",
              " 40833: 'localized',\n",
              " 30571: 'disobeying',\n",
              " 52013: \"'royale\",\n",
              " 40834: \"harpo's\",\n",
              " 52014: 'canet',\n",
              " 19316: 'aileen',\n",
              " 52015: 'acurately',\n",
              " 52016: \"diplomat's\",\n",
              " 25245: 'rickman',\n",
              " 6749: 'arranged',\n",
              " 52017: 'rumbustious',\n",
              " 52018: 'familiarness',\n",
              " 52019: \"spider'\",\n",
              " 68807: 'hahahah',\n",
              " 52020: \"wood'\",\n",
              " 40836: 'transvestism',\n",
              " 34705: \"hangin'\",\n",
              " 2341: 'bringing',\n",
              " 40837: 'seamier',\n",
              " 34706: 'wooded',\n",
              " 52021: 'bravora',\n",
              " 16820: 'grueling',\n",
              " 1639: 'wooden',\n",
              " 16821: 'wednesday',\n",
              " 52022: \"'prix\",\n",
              " 34707: 'altagracia',\n",
              " 52023: 'circuitry',\n",
              " 11588: 'crotch',\n",
              " 57769: 'busybody',\n",
              " 52024: \"tart'n'tangy\",\n",
              " 14132: 'burgade',\n",
              " 52026: 'thrace',\n",
              " 11041: \"tom's\",\n",
              " 52028: 'snuggles',\n",
              " 29117: 'francesco',\n",
              " 52030: 'complainers',\n",
              " 52128: 'templarios',\n",
              " 40838: '272',\n",
              " 52031: '273',\n",
              " 52133: 'zaniacs',\n",
              " 34709: '275',\n",
              " 27634: 'consenting',\n",
              " 40839: 'snuggled',\n",
              " 15495: 'inanimate',\n",
              " 52033: 'uality',\n",
              " 11929: 'bronte',\n",
              " 4013: 'errors',\n",
              " 3233: 'dialogs',\n",
              " 52034: \"yomada's\",\n",
              " 34710: \"madman's\",\n",
              " 30588: 'dialoge',\n",
              " 52036: 'usenet',\n",
              " 40840: 'videodrome',\n",
              " 26341: \"kid'\",\n",
              " 52037: 'pawed',\n",
              " 30572: \"'girlfriend'\",\n",
              " 52038: \"'pleasure\",\n",
              " 52039: \"'reloaded'\",\n",
              " 40842: \"kazakos'\",\n",
              " 52040: 'rocque',\n",
              " 52041: 'mailings',\n",
              " 11930: 'brainwashed',\n",
              " 16822: 'mcanally',\n",
              " 52042: \"tom''\",\n",
              " 25246: 'kurupt',\n",
              " 21908: 'affiliated',\n",
              " 52043: 'babaganoosh',\n",
              " 40843: \"noe's\",\n",
              " 40844: 'quart',\n",
              " 362: 'kids',\n",
              " 5037: 'uplifting',\n",
              " 7096: 'controversy',\n",
              " 21909: 'kida',\n",
              " 23382: 'kidd',\n",
              " 52044: \"error'\",\n",
              " 52045: 'neurologist',\n",
              " 18513: 'spotty',\n",
              " 30573: 'cobblers',\n",
              " 9881: 'projection',\n",
              " 40845: 'fastforwarding',\n",
              " 52046: 'sters',\n",
              " 52047: \"eggar's\",\n",
              " 52048: 'etherything',\n",
              " 40846: 'gateshead',\n",
              " 34711: 'airball',\n",
              " 25247: 'unsinkable',\n",
              " 7183: 'stern',\n",
              " 52049: \"cervi's\",\n",
              " 40847: 'dnd',\n",
              " 11589: 'dna',\n",
              " 20601: 'insecurity',\n",
              " 52050: \"'reboot'\",\n",
              " 11040: 'trelkovsky',\n",
              " 52051: 'jaekel',\n",
              " 52052: 'sidebars',\n",
              " 52053: \"sforza's\",\n",
              " 17636: 'distortions',\n",
              " 52054: 'mutinies',\n",
              " 30605: 'sermons',\n",
              " 40849: '7ft',\n",
              " 52055: 'boobage',\n",
              " 52056: \"o'bannon's\",\n",
              " 23383: 'populations',\n",
              " 52057: 'chulak',\n",
              " 27636: 'mesmerize',\n",
              " 52058: 'quinnell',\n",
              " 10310: 'yahoo',\n",
              " 52060: 'meteorologist',\n",
              " 42580: 'beswick',\n",
              " 15496: 'boorman',\n",
              " 40850: 'voicework',\n",
              " 52061: \"ster'\",\n",
              " 22925: 'blustering',\n",
              " 52062: 'hj',\n",
              " 27637: 'intake',\n",
              " 5624: 'morally',\n",
              " 40852: 'jumbling',\n",
              " 52063: 'bowersock',\n",
              " 52064: \"'porky's'\",\n",
              " 16824: 'gershon',\n",
              " 40853: 'ludicrosity',\n",
              " 52065: 'coprophilia',\n",
              " 40854: 'expressively',\n",
              " 19503: \"india's\",\n",
              " 34713: \"post's\",\n",
              " 52066: 'wana',\n",
              " 5286: 'wang',\n",
              " 30574: 'wand',\n",
              " 25248: 'wane',\n",
              " 52324: 'edgeways',\n",
              " 34714: 'titanium',\n",
              " 40855: 'pinta',\n",
              " 181: 'want',\n",
              " 30575: 'pinto',\n",
              " 52068: 'whoopdedoodles',\n",
              " 21911: 'tchaikovsky',\n",
              " 2106: 'travel',\n",
              " 52069: \"'victory'\",\n",
              " 11931: 'copious',\n",
              " 22436: 'gouge',\n",
              " 52070: \"chapters'\",\n",
              " 6705: 'barbra',\n",
              " 30576: 'uselessness',\n",
              " 52071: \"wan'\",\n",
              " 27638: 'assimilated',\n",
              " 16119: 'petiot',\n",
              " 52072: 'most\\x85and',\n",
              " 3933: 'dinosaurs',\n",
              " 355: 'wrong',\n",
              " 52073: 'seda',\n",
              " 52074: 'stollen',\n",
              " 34715: 'sentencing',\n",
              " 40856: 'ouroboros',\n",
              " 40857: 'assimilates',\n",
              " 40858: 'colorfully',\n",
              " 27639: 'glenne',\n",
              " 52075: 'dongen',\n",
              " 4763: 'subplots',\n",
              " 52076: 'kiloton',\n",
              " 23384: 'chandon',\n",
              " 34716: \"effect'\",\n",
              " 27640: 'snugly',\n",
              " 40859: 'kuei',\n",
              " 9095: 'welcomed',\n",
              " 30074: 'dishonor',\n",
              " 52078: 'concurrence',\n",
              " 23385: 'stoicism',\n",
              " 14899: \"guys'\",\n",
              " 52080: \"beroemd'\",\n",
              " 6706: 'butcher',\n",
              " 40860: \"melfi's\",\n",
              " 30626: 'aargh',\n",
              " 20602: 'playhouse',\n",
              " 11311: 'wickedly',\n",
              " 1183: 'fit',\n",
              " 52081: 'labratory',\n",
              " 40862: 'lifeline',\n",
              " 1930: 'screaming',\n",
              " 4290: 'fix',\n",
              " 52082: 'cineliterate',\n",
              " 52083: 'fic',\n",
              " 52084: 'fia',\n",
              " 34717: 'fig',\n",
              " 52085: 'fmvs',\n",
              " 52086: 'fie',\n",
              " 52087: 'reentered',\n",
              " 30577: 'fin',\n",
              " 52088: 'doctresses',\n",
              " 52089: 'fil',\n",
              " 12609: 'zucker',\n",
              " 31934: 'ached',\n",
              " 52091: 'counsil',\n",
              " 52092: 'paterfamilias',\n",
              " 13888: 'songwriter',\n",
              " 34718: 'shivam',\n",
              " 9657: 'hurting',\n",
              " 302: 'effects',\n",
              " 52093: 'slauther',\n",
              " 52094: \"'flame'\",\n",
              " 52095: 'sommerset',\n",
              " 52096: 'interwhined',\n",
              " 27641: 'whacking',\n",
              " 52097: 'bartok',\n",
              " 8778: 'barton',\n",
              " 21912: 'frewer',\n",
              " 52098: \"fi'\",\n",
              " 6195: 'ingrid',\n",
              " 30578: 'stribor',\n",
              " 52099: 'approporiately',\n",
              " 52100: 'wobblyhand',\n",
              " 52101: 'tantalisingly',\n",
              " 52102: 'ankylosaurus',\n",
              " 17637: 'parasites',\n",
              " 52103: 'childen',\n",
              " 52104: \"jenkins'\",\n",
              " 52105: 'metafiction',\n",
              " 17638: 'golem',\n",
              " 40863: 'indiscretion',\n",
              " 23386: \"reeves'\",\n",
              " 57784: \"inamorata's\",\n",
              " 52107: 'brittannica',\n",
              " 7919: 'adapt',\n",
              " 30579: \"russo's\",\n",
              " 48249: 'guitarists',\n",
              " 10556: 'abbott',\n",
              " 40864: 'abbots',\n",
              " 17652: 'lanisha',\n",
              " 40866: 'magickal',\n",
              " 52108: 'mattter',\n",
              " 52109: \"'willy\",\n",
              " 34719: 'pumpkins',\n",
              " 52110: 'stuntpeople',\n",
              " 30580: 'estimate',\n",
              " 40867: 'ugghhh',\n",
              " 11312: 'gameplay',\n",
              " 52111: \"wern't\",\n",
              " 40868: \"n'sync\",\n",
              " 16120: 'sickeningly',\n",
              " 40869: 'chiara',\n",
              " 4014: 'disturbed',\n",
              " 40870: 'portmanteau',\n",
              " 52112: 'ineffectively',\n",
              " 82146: \"duchonvey's\",\n",
              " 37522: \"nasty'\",\n",
              " 1288: 'purpose',\n",
              " 52115: 'lazers',\n",
              " 28108: 'lightened',\n",
              " 52116: 'kaliganj',\n",
              " 52117: 'popularism',\n",
              " 18514: \"damme's\",\n",
              " 30581: 'stylistics',\n",
              " 52118: 'mindgaming',\n",
              " 46452: 'spoilerish',\n",
              " 52120: \"'corny'\",\n",
              " 34721: 'boerner',\n",
              " 6795: 'olds',\n",
              " 52121: 'bakelite',\n",
              " 27642: 'renovated',\n",
              " 27643: 'forrester',\n",
              " 52122: \"lumiere's\",\n",
              " 52027: 'gaskets',\n",
              " 887: 'needed',\n",
              " 34722: 'smight',\n",
              " 1300: 'master',\n",
              " 25908: \"edie's\",\n",
              " 40871: 'seeber',\n",
              " 52123: 'hiya',\n",
              " 52124: 'fuzziness',\n",
              " 14900: 'genesis',\n",
              " 12610: 'rewards',\n",
              " 30582: 'enthrall',\n",
              " 40872: \"'about\",\n",
              " 52125: \"recollection's\",\n",
              " 11042: 'mutilated',\n",
              " 52126: 'fatherlands',\n",
              " 52127: \"fischer's\",\n",
              " 5402: 'positively',\n",
              " 34708: '270',\n",
              " 34723: 'ahmed',\n",
              " 9839: 'zatoichi',\n",
              " 13889: 'bannister',\n",
              " 52130: 'anniversaries',\n",
              " 30583: \"helm's\",\n",
              " 52131: \"'work'\",\n",
              " 34724: 'exclaimed',\n",
              " 52132: \"'unfunny'\",\n",
              " 52032: '274',\n",
              " 547: 'feeling',\n",
              " 52134: \"wanda's\",\n",
              " 33269: 'dolan',\n",
              " 52136: '278',\n",
              " 52137: 'peacoat',\n",
              " 40873: 'brawny',\n",
              " 40874: 'mishra',\n",
              " 40875: 'worlders',\n",
              " 52138: 'protags',\n",
              " 52139: 'skullcap',\n",
              " 57599: 'dastagir',\n",
              " 5625: 'affairs',\n",
              " 7802: 'wholesome',\n",
              " 52140: 'hymen',\n",
              " 25249: 'paramedics',\n",
              " 52141: 'unpersons',\n",
              " 52142: 'heavyarms',\n",
              " 52143: 'affaire',\n",
              " 52144: 'coulisses',\n",
              " 40876: 'hymer',\n",
              " 52145: 'kremlin',\n",
              " 30584: 'shipments',\n",
              " 52146: 'pixilated',\n",
              " 30585: \"'00s\",\n",
              " 18515: 'diminishing',\n",
              " 1360: 'cinematic',\n",
              " 14901: 'resonates',\n",
              " 40877: 'simplify',\n",
              " 40878: \"nature'\",\n",
              " 40879: 'temptresses',\n",
              " 16825: 'reverence',\n",
              " 19505: 'resonated',\n",
              " 34725: 'dailey',\n",
              " 52147: '2\\x85',\n",
              " 27644: 'treize',\n",
              " 52148: 'majo',\n",
              " 21913: 'kiya',\n",
              " 52149: 'woolnough',\n",
              " 39800: 'thanatos',\n",
              " 35734: 'sandoval',\n",
              " 40882: 'dorama',\n",
              " 52150: \"o'shaughnessy\",\n",
              " 4991: 'tech',\n",
              " 32021: 'fugitives',\n",
              " 30586: 'teck',\n",
              " 76128: \"'e'\",\n",
              " 40884: 'doesn’t',\n",
              " 52152: 'purged',\n",
              " 660: 'saying',\n",
              " 41098: \"martians'\",\n",
              " 23421: 'norliss',\n",
              " 27645: 'dickey',\n",
              " 52155: 'dicker',\n",
              " 52156: \"'sependipity\",\n",
              " 8425: 'padded',\n",
              " 57795: 'ordell',\n",
              " 40885: \"sturges'\",\n",
              " 52157: 'independentcritics',\n",
              " 5748: 'tempted',\n",
              " 34727: \"atkinson's\",\n",
              " 25250: 'hounded',\n",
              " 52158: 'apace',\n",
              " 15497: 'clicked',\n",
              " 30587: \"'humor'\",\n",
              " 17180: \"martino's\",\n",
              " 52159: \"'supporting\",\n",
              " 52035: 'warmongering',\n",
              " 34728: \"zemeckis's\",\n",
              " 21914: 'lube',\n",
              " 52160: 'shocky',\n",
              " 7479: 'plate',\n",
              " 40886: 'plata',\n",
              " 40887: 'sturgess',\n",
              " 40888: \"nerds'\",\n",
              " 20603: 'plato',\n",
              " 34729: 'plath',\n",
              " 40889: 'platt',\n",
              " 52162: 'mcnab',\n",
              " 27646: 'clumsiness',\n",
              " 3902: 'altogether',\n",
              " 42587: 'massacring',\n",
              " 52163: 'bicenntinial',\n",
              " 40890: 'skaal',\n",
              " 14363: 'droning',\n",
              " 8779: 'lds',\n",
              " 21915: 'jaguar',\n",
              " 34730: \"cale's\",\n",
              " 1780: 'nicely',\n",
              " 4591: 'mummy',\n",
              " 18516: \"lot's\",\n",
              " 10089: 'patch',\n",
              " 50205: 'kerkhof',\n",
              " 52164: \"leader's\",\n",
              " 27647: \"'movie\",\n",
              " 52165: 'uncomfirmed',\n",
              " 40891: 'heirloom',\n",
              " 47363: 'wrangle',\n",
              " 52166: 'emotion\\x85',\n",
              " 52167: \"'stargate'\",\n",
              " 40892: 'pinoy',\n",
              " 40893: 'conchatta',\n",
              " 41131: 'broeke',\n",
              " 40894: 'advisedly',\n",
              " 17639: \"barker's\",\n",
              " 52169: 'descours',\n",
              " 775: 'lots',\n",
              " 9262: 'lotr',\n",
              " 9882: 'irs',\n",
              " 52170: 'lott',\n",
              " 40895: 'xvi',\n",
              " 34731: 'irk',\n",
              " 52171: 'irl',\n",
              " 6890: 'ira',\n",
              " 21916: 'belzer',\n",
              " 52172: 'irc',\n",
              " 27648: 'ire',\n",
              " 40896: 'requisites',\n",
              " 7696: 'discipline',\n",
              " 52964: 'lyoko',\n",
              " 11313: 'extend',\n",
              " 876: 'nature',\n",
              " 52173: \"'dickie'\",\n",
              " 40897: 'optimist',\n",
              " 30589: 'lapping',\n",
              " 3903: 'superficial',\n",
              " 52174: 'vestment',\n",
              " 2826: 'extent',\n",
              " 52175: 'tendons',\n",
              " 52176: \"heller's\",\n",
              " 52177: 'quagmires',\n",
              " 52178: 'miyako',\n",
              " 20604: 'moocow',\n",
              " 52179: \"coles'\",\n",
              " 40898: 'lookit',\n",
              " 52180: 'ravenously',\n",
              " 40899: 'levitating',\n",
              " 52181: 'perfunctorily',\n",
              " 30590: 'lookin',\n",
              " 40901: \"lot'\",\n",
              " 52182: 'lookie',\n",
              " 34873: 'fearlessly',\n",
              " 52184: 'libyan',\n",
              " 40902: 'fondles',\n",
              " 35717: 'gopher',\n",
              " 40904: 'wearying',\n",
              " 52185: \"nz's\",\n",
              " 27649: 'minuses',\n",
              " 52186: 'puposelessly',\n",
              " 52187: 'shandling',\n",
              " 31271: 'decapitates',\n",
              " 11932: 'humming',\n",
              " 40905: \"'nother\",\n",
              " 21917: 'smackdown',\n",
              " 30591: 'underdone',\n",
              " 40906: 'frf',\n",
              " 52188: 'triviality',\n",
              " 25251: 'fro',\n",
              " 8780: 'bothers',\n",
              " 52189: \"'kensington\",\n",
              " 76: 'much',\n",
              " 34733: 'muco',\n",
              " 22618: 'wiseguy',\n",
              " 27651: \"richie's\",\n",
              " 40907: 'tonino',\n",
              " 52190: 'unleavened',\n",
              " 11590: 'fry',\n",
              " 40908: \"'tv'\",\n",
              " 40909: 'toning',\n",
              " 14364: 'obese',\n",
              " 30592: 'sensationalized',\n",
              " 40910: 'spiv',\n",
              " 6262: 'spit',\n",
              " 7367: 'arkin',\n",
              " 21918: 'charleton',\n",
              " 16826: 'jeon',\n",
              " 21919: 'boardroom',\n",
              " 4992: 'doubts',\n",
              " 3087: 'spin',\n",
              " 53086: 'hepo',\n",
              " 27652: 'wildcat',\n",
              " 10587: 'venoms',\n",
              " 52194: 'misconstrues',\n",
              " 18517: 'mesmerising',\n",
              " 40911: 'misconstrued',\n",
              " 52195: 'rescinds',\n",
              " 52196: 'prostrate',\n",
              " 40912: 'majid',\n",
              " 16482: 'climbed',\n",
              " 34734: 'canoeing',\n",
              " 52198: 'majin',\n",
              " 57807: 'animie',\n",
              " 40913: 'sylke',\n",
              " 14902: 'conditioned',\n",
              " 40914: 'waddell',\n",
              " 52199: '3\\x85',\n",
              " 41191: 'hyperdrive',\n",
              " 34735: 'conditioner',\n",
              " 53156: 'bricklayer',\n",
              " 2579: 'hong',\n",
              " 52201: 'memoriam',\n",
              " 30595: 'inventively',\n",
              " 25252: \"levant's\",\n",
              " 20641: 'portobello',\n",
              " 52203: 'remand',\n",
              " 19507: 'mummified',\n",
              " 27653: 'honk',\n",
              " 19508: 'spews',\n",
              " 40915: 'visitations',\n",
              " 52204: 'mummifies',\n",
              " 25253: 'cavanaugh',\n",
              " 23388: 'zeon',\n",
              " 40916: \"jungle's\",\n",
              " 34736: 'viertel',\n",
              " 27654: 'frenchmen',\n",
              " 52205: 'torpedoes',\n",
              " 52206: 'schlessinger',\n",
              " 34737: 'torpedoed',\n",
              " 69879: 'blister',\n",
              " 52207: 'cinefest',\n",
              " 34738: 'furlough',\n",
              " 52208: 'mainsequence',\n",
              " 40917: 'mentors',\n",
              " 9097: 'academic',\n",
              " 20605: 'stillness',\n",
              " 40918: 'academia',\n",
              " 52209: 'lonelier',\n",
              " 52210: 'nibby',\n",
              " 52211: \"losers'\",\n",
              " 40919: 'cineastes',\n",
              " 4452: 'corporate',\n",
              " 40920: 'massaging',\n",
              " 30596: 'bellow',\n",
              " 19509: 'absurdities',\n",
              " 53244: 'expetations',\n",
              " 40921: 'nyfiken',\n",
              " 75641: 'mehras',\n",
              " 52212: 'lasse',\n",
              " 52213: 'visability',\n",
              " 33949: 'militarily',\n",
              " 52214: \"elder'\",\n",
              " 19026: 'gainsbourg',\n",
              " 20606: 'hah',\n",
              " 13423: 'hai',\n",
              " 34739: 'haj',\n",
              " 25254: 'hak',\n",
              " 4314: 'hal',\n",
              " 4895: 'ham',\n",
              " 53262: 'duffer',\n",
              " 52216: 'haa',\n",
              " 69: 'had',\n",
              " 11933: 'advancement',\n",
              " 16828: 'hag',\n",
              " 25255: \"hand'\",\n",
              " 13424: 'hay',\n",
              " 20607: 'mcnamara',\n",
              " 52217: \"mozart's\",\n",
              " 30734: 'duffel',\n",
              " 30597: 'haq',\n",
              " 13890: 'har',\n",
              " 47: 'has',\n",
              " 2404: 'hat',\n",
              " 40922: 'hav',\n",
              " 30598: 'haw',\n",
              " 52218: 'figtings',\n",
              " 15498: 'elders',\n",
              " 52219: 'underpanted',\n",
              " 52220: 'pninson',\n",
              " 27655: 'unequivocally',\n",
              " 23676: \"barbara's\",\n",
              " 52222: \"bello'\",\n",
              " 13000: 'indicative',\n",
              " 40923: 'yawnfest',\n",
              " 52223: 'hexploitation',\n",
              " 52224: \"loder's\",\n",
              " 27656: 'sleuthing',\n",
              " 32625: \"justin's\",\n",
              " 52225: \"'ball\",\n",
              " 52226: \"'summer\",\n",
              " 34938: \"'demons'\",\n",
              " 52228: \"mormon's\",\n",
              " 34740: \"laughton's\",\n",
              " 52229: 'debell',\n",
              " 39727: 'shipyard',\n",
              " 30600: 'unabashedly',\n",
              " 40404: 'disks',\n",
              " 2293: 'crowd',\n",
              " 10090: 'crowe',\n",
              " 56437: \"vancouver's\",\n",
              " 34741: 'mosques',\n",
              " 6630: 'crown',\n",
              " 52230: 'culpas',\n",
              " 27657: 'crows',\n",
              " 53347: 'surrell',\n",
              " 52232: 'flowless',\n",
              " 52233: 'sheirk',\n",
              " 40926: \"'three\",\n",
              " 52234: \"peterson'\",\n",
              " 52235: 'ooverall',\n",
              " 40927: 'perchance',\n",
              " 1324: 'bottom',\n",
              " 53366: 'chabert',\n",
              " 52236: 'sneha',\n",
              " 13891: 'inhuman',\n",
              " 52237: 'ichii',\n",
              " 52238: 'ursla',\n",
              " 30601: 'completly',\n",
              " 40928: 'moviedom',\n",
              " 52239: 'raddick',\n",
              " 51998: 'brundage',\n",
              " 40929: 'brigades',\n",
              " 1184: 'starring',\n",
              " 52240: \"'goal'\",\n",
              " 52241: 'caskets',\n",
              " 52242: 'willcock',\n",
              " 52243: \"threesome's\",\n",
              " 52244: \"mosque'\",\n",
              " 52245: \"cover's\",\n",
              " 17640: 'spaceships',\n",
              " 40930: 'anomalous',\n",
              " 27658: 'ptsd',\n",
              " 52246: 'shirdan',\n",
              " 21965: 'obscenity',\n",
              " 30602: 'lemmings',\n",
              " 30603: 'duccio',\n",
              " 52247: \"levene's\",\n",
              " 52248: \"'gorby'\",\n",
              " 25258: \"teenager's\",\n",
              " 5343: 'marshall',\n",
              " 9098: 'honeymoon',\n",
              " 3234: 'shoots',\n",
              " 12261: 'despised',\n",
              " 52249: 'okabasho',\n",
              " 8292: 'fabric',\n",
              " 18518: 'cannavale',\n",
              " 3540: 'raped',\n",
              " 52250: \"tutt's\",\n",
              " 17641: 'grasping',\n",
              " 18519: 'despises',\n",
              " 40931: \"thief's\",\n",
              " 8929: 'rapes',\n",
              " 52251: 'raper',\n",
              " 27659: \"eyre'\",\n",
              " 52252: 'walchek',\n",
              " 23389: \"elmo's\",\n",
              " 40932: 'perfumes',\n",
              " 21921: 'spurting',\n",
              " 52253: \"exposition'\\x85\",\n",
              " 52254: 'denoting',\n",
              " 34743: 'thesaurus',\n",
              " 40933: \"shoot'\",\n",
              " 49762: 'bonejack',\n",
              " 52256: 'simpsonian',\n",
              " 30604: 'hebetude',\n",
              " 34744: \"hallow's\",\n",
              " 52257: 'desperation\\x85',\n",
              " 34745: 'incinerator',\n",
              " 10311: 'congratulations',\n",
              " 52258: 'humbled',\n",
              " 5927: \"else's\",\n",
              " 40848: 'trelkovski',\n",
              " 52259: \"rape'\",\n",
              " 59389: \"'chapters'\",\n",
              " 52260: '1600s',\n",
              " 7256: 'martian',\n",
              " 25259: 'nicest',\n",
              " 52262: 'eyred',\n",
              " 9460: 'passenger',\n",
              " 6044: 'disgrace',\n",
              " 52263: 'moderne',\n",
              " 5123: 'barrymore',\n",
              " 52264: 'yankovich',\n",
              " 40934: 'moderns',\n",
              " 52265: 'studliest',\n",
              " 52266: 'bedsheet',\n",
              " 14903: 'decapitation',\n",
              " 52267: 'slurring',\n",
              " 52268: \"'nunsploitation'\",\n",
              " 34746: \"'character'\",\n",
              " 9883: 'cambodia',\n",
              " 52269: 'rebelious',\n",
              " 27660: 'pasadena',\n",
              " 40935: 'crowne',\n",
              " 52270: \"'bedchamber\",\n",
              " 52271: 'conjectural',\n",
              " 52272: 'appologize',\n",
              " 52273: 'halfassing',\n",
              " 57819: 'paycheque',\n",
              " 20609: 'palms',\n",
              " 52274: \"'islands\",\n",
              " 40936: 'hawked',\n",
              " 21922: 'palme',\n",
              " 40937: 'conservatively',\n",
              " 64010: 'larp',\n",
              " 5561: 'palma',\n",
              " 21923: 'smelling',\n",
              " 13001: 'aragorn',\n",
              " 52275: 'hawker',\n",
              " 52276: 'hawkes',\n",
              " 3978: 'explosions',\n",
              " 8062: 'loren',\n",
              " 52277: \"pyle's\",\n",
              " 6707: 'shootout',\n",
              " 18520: \"mike's\",\n",
              " 52278: \"driscoll's\",\n",
              " 40938: 'cogsworth',\n",
              " 52279: \"britian's\",\n",
              " 34747: 'childs',\n",
              " 52280: \"portrait's\",\n",
              " 3629: 'chain',\n",
              " 2500: 'whoever',\n",
              " 52281: 'puttered',\n",
              " 52282: 'childe',\n",
              " 52283: 'maywether',\n",
              " 3039: 'chair',\n",
              " 52284: \"rance's\",\n",
              " 34748: 'machu',\n",
              " 4520: 'ballet',\n",
              " 34749: 'grapples',\n",
              " 76155: 'summerize',\n",
              " 30606: 'freelance',\n",
              " 52286: \"andrea's\",\n",
              " 52287: '\\x91very',\n",
              " 45882: 'coolidge',\n",
              " 18521: 'mache',\n",
              " 52288: 'balled',\n",
              " 40940: 'grappled',\n",
              " 18522: 'macha',\n",
              " 21924: 'underlining',\n",
              " 5626: 'macho',\n",
              " 19510: 'oversight',\n",
              " 25260: 'machi',\n",
              " 11314: 'verbally',\n",
              " 21925: 'tenacious',\n",
              " 40941: 'windshields',\n",
              " 18560: 'paychecks',\n",
              " 3399: 'jerk',\n",
              " 11934: \"good'\",\n",
              " 34751: 'prancer',\n",
              " 21926: 'prances',\n",
              " 52289: 'olympus',\n",
              " 21927: 'lark',\n",
              " 10788: 'embark',\n",
              " 7368: 'gloomy',\n",
              " 52290: 'jehaan',\n",
              " 52291: 'turaqui',\n",
              " 20610: \"child'\",\n",
              " 2897: 'locked',\n",
              " 52292: 'pranced',\n",
              " 2591: 'exact',\n",
              " 52293: 'unattuned',\n",
              " 786: 'minute',\n",
              " 16121: 'skewed',\n",
              " 40943: 'hodgins',\n",
              " 34752: 'skewer',\n",
              " 52294: 'think\\x85',\n",
              " 38768: 'rosenstein',\n",
              " 52295: 'helmit',\n",
              " 34753: 'wrestlemanias',\n",
              " 16829: 'hindered',\n",
              " 30607: \"martha's\",\n",
              " 52296: 'cheree',\n",
              " 52297: \"pluckin'\",\n",
              " 40944: 'ogles',\n",
              " 11935: 'heavyweight',\n",
              " 82193: 'aada',\n",
              " 11315: 'chopping',\n",
              " 61537: 'strongboy',\n",
              " 41345: 'hegemonic',\n",
              " 40945: 'adorns',\n",
              " 41349: 'xxth',\n",
              " 34754: 'nobuhiro',\n",
              " 52301: 'capitães',\n",
              " 52302: 'kavogianni',\n",
              " 13425: 'antwerp',\n",
              " 6541: 'celebrated',\n",
              " 52303: 'roarke',\n",
              " 40946: 'baggins',\n",
              " 31273: 'cheeseburgers',\n",
              " 52304: 'matras',\n",
              " 52305: \"nineties'\",\n",
              " 52306: \"'craig'\",\n",
              " 13002: 'celebrates',\n",
              " 3386: 'unintentionally',\n",
              " 14365: 'drafted',\n",
              " 52307: 'climby',\n",
              " 52308: '303',\n",
              " 18523: 'oldies',\n",
              " 9099: 'climbs',\n",
              " 9658: 'honour',\n",
              " 34755: 'plucking',\n",
              " 30077: '305',\n",
              " 5517: 'address',\n",
              " 40947: 'menjou',\n",
              " 42595: \"'freak'\",\n",
              " 19511: 'dwindling',\n",
              " 9461: 'benson',\n",
              " 52310: 'white’s',\n",
              " 40948: 'shamelessness',\n",
              " 21928: 'impacted',\n",
              " 52311: 'upatz',\n",
              " 3843: 'cusack',\n",
              " 37570: \"flavia's\",\n",
              " 52312: 'effette',\n",
              " 34756: 'influx',\n",
              " 52313: 'boooooooo',\n",
              " 52314: 'dimitrova',\n",
              " 13426: 'houseman',\n",
              " 25262: 'bigas',\n",
              " 52315: 'boylen',\n",
              " 52316: 'phillipenes',\n",
              " 40949: 'fakery',\n",
              " 27661: \"grandpa's\",\n",
              " 27662: 'darnell',\n",
              " 19512: 'undergone',\n",
              " 52318: 'handbags',\n",
              " 21929: 'perished',\n",
              " 37781: 'pooped',\n",
              " 27663: 'vigour',\n",
              " 3630: 'opposed',\n",
              " 52319: 'etude',\n",
              " 11802: \"caine's\",\n",
              " 52320: 'doozers',\n",
              " 34757: 'photojournals',\n",
              " 52321: 'perishes',\n",
              " 34758: 'constrains',\n",
              " 40951: 'migenes',\n",
              " 30608: 'consoled',\n",
              " 16830: 'alastair',\n",
              " 52322: 'wvs',\n",
              " 52323: 'ooooooh',\n",
              " 34759: 'approving',\n",
              " 40952: 'consoles',\n",
              " 52067: 'disparagement',\n",
              " 52325: 'futureistic',\n",
              " 52326: 'rebounding',\n",
              " 52327: \"'date\",\n",
              " 52328: 'gregoire',\n",
              " 21930: 'rutherford',\n",
              " 34760: 'americanised',\n",
              " 82199: 'novikov',\n",
              " 1045: 'following',\n",
              " 34761: 'munroe',\n",
              " 52329: \"morita'\",\n",
              " 52330: 'christenssen',\n",
              " 23109: 'oatmeal',\n",
              " 25263: 'fossey',\n",
              " 40953: 'livered',\n",
              " 13003: 'listens',\n",
              " 76167: \"'marci\",\n",
              " 52333: \"otis's\",\n",
              " 23390: 'thanking',\n",
              " 16022: 'maude',\n",
              " 34762: 'extensions',\n",
              " 52335: 'ameteurish',\n",
              " 52336: \"commender's\",\n",
              " 27664: 'agricultural',\n",
              " 4521: 'convincingly',\n",
              " 17642: 'fueled',\n",
              " 54017: 'mahattan',\n",
              " 40955: \"paris's\",\n",
              " 52339: 'vulkan',\n",
              " 52340: 'stapes',\n",
              " 52341: 'odysessy',\n",
              " 12262: 'harmon',\n",
              " 4255: 'surfing',\n",
              " 23497: 'halloran',\n",
              " 49583: 'unbelieveably',\n",
              " 52342: \"'offed'\",\n",
              " 30610: 'quadrant',\n",
              " 19513: 'inhabiting',\n",
              " 34763: 'nebbish',\n",
              " 40956: 'forebears',\n",
              " 34764: 'skirmish',\n",
              " 52343: 'ocassionally',\n",
              " 52344: \"'resist\",\n",
              " 21931: 'impactful',\n",
              " 52345: 'spicier',\n",
              " 40957: 'touristy',\n",
              " 52346: \"'football'\",\n",
              " 40958: 'webpage',\n",
              " 52348: 'exurbia',\n",
              " 52349: 'jucier',\n",
              " 14904: 'professors',\n",
              " 34765: 'structuring',\n",
              " 30611: 'jig',\n",
              " 40959: 'overlord',\n",
              " 25264: 'disconnect',\n",
              " 82204: 'sniffle',\n",
              " 40960: 'slimeball',\n",
              " 40961: 'jia',\n",
              " 16831: 'milked',\n",
              " 40962: 'banjoes',\n",
              " 1240: 'jim',\n",
              " 52351: 'workforces',\n",
              " 52352: 'jip',\n",
              " 52353: 'rotweiller',\n",
              " 34766: 'mundaneness',\n",
              " 52354: \"'ninja'\",\n",
              " 11043: \"dead'\",\n",
              " 40963: \"cipriani's\",\n",
              " 20611: 'modestly',\n",
              " 52355: \"professor'\",\n",
              " 40964: 'shacked',\n",
              " 34767: 'bashful',\n",
              " 23391: 'sorter',\n",
              " 16123: 'overpowering',\n",
              " 18524: 'workmanlike',\n",
              " 27665: 'henpecked',\n",
              " 18525: 'sorted',\n",
              " 52357: \"jōb's\",\n",
              " 52358: \"'always\",\n",
              " 34768: \"'baptists\",\n",
              " 52359: 'dreamcatchers',\n",
              " 52360: \"'silence'\",\n",
              " 21932: 'hickory',\n",
              " 52361: 'fun\\x97yet',\n",
              " 52362: 'breakumentary',\n",
              " 15499: 'didn',\n",
              " 52363: 'didi',\n",
              " 52364: 'pealing',\n",
              " 40965: 'dispite',\n",
              " 25265: \"italy's\",\n",
              " 21933: 'instability',\n",
              " 6542: 'quarter',\n",
              " 12611: 'quartet',\n",
              " 52365: 'padmé',\n",
              " 52366: \"'bleedmedry\",\n",
              " 52367: 'pahalniuk',\n",
              " 52368: 'honduras',\n",
              " 10789: 'bursting',\n",
              " 41468: \"pablo's\",\n",
              " 52370: 'irremediably',\n",
              " 40966: 'presages',\n",
              " 57835: 'bowlegged',\n",
              " 65186: 'dalip',\n",
              " 6263: 'entering',\n",
              " 76175: 'newsradio',\n",
              " 54153: 'presaged',\n",
              " 27666: \"giallo's\",\n",
              " 40967: 'bouyant',\n",
              " 52371: 'amerterish',\n",
              " 18526: 'rajni',\n",
              " 30613: 'leeves',\n",
              " 34770: 'macauley',\n",
              " 615: 'seriously',\n",
              " 52372: 'sugercoma',\n",
              " 52373: 'grimstead',\n",
              " 52374: \"'fairy'\",\n",
              " 30614: 'zenda',\n",
              " 52375: \"'twins'\",\n",
              " 17643: 'realisation',\n",
              " 27667: 'highsmith',\n",
              " 7820: 'raunchy',\n",
              " 40968: 'incentives',\n",
              " 52377: 'flatson',\n",
              " 35100: 'snooker',\n",
              " 16832: 'crazies',\n",
              " 14905: 'crazier',\n",
              " 7097: 'grandma',\n",
              " 52378: 'napunsaktha',\n",
              " 30615: 'workmanship',\n",
              " 52379: 'reisner',\n",
              " 61309: \"sanford's\",\n",
              " 52380: '\\x91doña',\n",
              " 6111: 'modest',\n",
              " 19156: \"everything's\",\n",
              " 40969: 'hamer',\n",
              " 52382: \"couldn't'\",\n",
              " 13004: 'quibble',\n",
              " 52383: 'socking',\n",
              " 21934: 'tingler',\n",
              " 52384: 'gutman',\n",
              " 40970: 'lachlan',\n",
              " 52385: 'tableaus',\n",
              " 52386: 'headbanger',\n",
              " 2850: 'spoken',\n",
              " 34771: 'cerebrally',\n",
              " 23493: \"'road\",\n",
              " 21935: 'tableaux',\n",
              " 40971: \"proust's\",\n",
              " 40972: 'periodical',\n",
              " 52388: \"shoveller's\",\n",
              " 25266: 'tamara',\n",
              " 17644: 'affords',\n",
              " 3252: 'concert',\n",
              " 87958: \"yara's\",\n",
              " 52389: 'someome',\n",
              " 8427: 'lingering',\n",
              " 41514: \"abraham's\",\n",
              " 34772: 'beesley',\n",
              " 34773: 'cherbourg',\n",
              " 28627: 'kagan',\n",
              " 9100: 'snatch',\n",
              " 9263: \"miyazaki's\",\n",
              " 25267: 'absorbs',\n",
              " 40973: \"koltai's\",\n",
              " 64030: 'tingled',\n",
              " 19514: 'crossroads',\n",
              " 16124: 'rehab',\n",
              " 52392: 'falworth',\n",
              " 52393: 'sequals',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy6n-uM2eCy2",
        "colab_type": "code",
        "outputId": "90de2730-bbde-4e37-9eeb-1297704ef68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(\"Train-set size: \", len(x_train))\n",
        "print(\"Test-set size:  \", len(x_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train-set size:  25000\n",
            "Test-set size:   25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZhMAgaNeCy5",
        "colab_type": "code",
        "outputId": "fc4512d7-a5b4-44a6-a282-b84e859b7db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 531
        }
      },
      "source": [
        "np.array(x_train[1])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    1,  194, 1153,  194, 8255,   78,  228,    5,    6, 1463,\n",
              "       4369, 5012,  134,   26,    4,  715,    8,  118, 1634,   14,  394,\n",
              "         20,   13,  119,  954,  189,  102,    5,  207,  110, 3103,   21,\n",
              "         14,   69,  188,    8,   30,   23,    7,    4,  249,  126,   93,\n",
              "          4,  114,    9, 2300, 1523,    5,  647,    4,  116,    9,   35,\n",
              "       8163,    4,  229,    9,  340, 1322,    4,  118,    9,    4,  130,\n",
              "       4901,   19,    4, 1002,    5,   89,   29,  952,   46,   37,    4,\n",
              "        455,    9,   45,   43,   38, 1543, 1905,  398,    4, 1649,   26,\n",
              "       6853,    5,  163,   11, 3215,    2,    4, 1153,    9,  194,  775,\n",
              "          7, 8255,    2,  349, 2637,  148,  605,    2, 8003,   15,  123,\n",
              "        125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
              "        228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
              "         11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
              "        656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
              "         32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
              "       1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
              "       1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
              "         16,  145,   95], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug161o1r0NOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dybtUgUReCy8",
        "colab_type": "text"
      },
      "source": [
        "## Build Keras Embedding Layer Model\n",
        "We can think of the Embedding layer as a dicionary that maps a index assigned to a word to a word vector. This layer is very flexible and can be used in a few ways:\n",
        "\n",
        "* The embedding layer can be used at the start of a larger deep learning model. \n",
        "* Also we could load pre-train word embeddings into the embedding layer when we create our model.\n",
        "* Use the embedding layer to train our own word2vec models.\n",
        "\n",
        "The keras embedding layer doesn't require us to onehot encode our words, instead we have to give each word a unqiue intger number as an id. For the imdb dataset we've loaded this has already been done, but if this wasn't the case we could use sklearn [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vziyZyyp0OFP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tML4H6bUv8YR",
        "colab_type": "code",
        "outputId": "e49e0be2-d7cf-4083-f819-6cb7f25e57c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "model = Sequential()\n",
        "embedding_size = 8"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgVWwuL8t-KX",
        "colab_type": "code",
        "outputId": "7ca56c82-14ef-4daf-8f36-b3d2ba067272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "model.add(Embedding(input_dim=vocab_size,\n",
        "                    output_dim=embedding_size,\n",
        "                    name='Embedding_layer'))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdnoHK0Yt-N4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.add(LSTM(units=16, return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=8, return_sequences=True))\n",
        "\n",
        "model.add(LSTM(units=4))\n",
        "\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "optimizer = Adam(lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_dkYQEMy6Mq",
        "colab_type": "code",
        "outputId": "753488af-6a85-4a33-e700-ab724e0d282d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFqMBQI_udBX",
        "colab_type": "code",
        "outputId": "ee5d8d4c-a7b0-4477-a1a0-236ac9decbb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Embedding_layer (Embedding)  (None, None, 8)           80000     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, None, 16)          1600      \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, None, 8)           800       \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 4)                 208       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 82,613\n",
            "Trainable params: 82,613\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9WyjYfHuc4L",
        "colab_type": "code",
        "outputId": "bbf13dca-a826-4931-cad7-64a507da0966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          validation_split=0.05, epochs=2, batch_size=64)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 23750 samples, validate on 1250 samples\n",
            "Epoch 1/2\n",
            "23750/23750 [==============================] - 421s 18ms/step - loss: 0.4538 - acc: 0.7950 - val_loss: 0.3466 - val_acc: 0.8616\n",
            "Epoch 2/2\n",
            "23750/23750 [==============================] - 402s 17ms/step - loss: 0.2547 - acc: 0.9055 - val_loss: 0.2958 - val_acc: 0.8752\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d98208588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS9PiELUt-F5",
        "colab_type": "code",
        "outputId": "c4970fd2-5b67-40e3-c18f-19579d8ae102",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "result = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25000/25000 [==============================] - 146s 6ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCGnKv8Y0g_T",
        "colab_type": "text"
      },
      "source": [
        "## Report the Accuracy of the model. (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3CSVVPPeCzD",
        "colab_type": "code",
        "outputId": "c7f12a7b-9d8a-46e2-f575-85006bdd0eb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Accuracy: {}\".format(result[1]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.871\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5OLM4eBeCy9",
        "colab_type": "code",
        "outputId": "7fc82261-4cc8-4e87-d0a5-093b0a5008d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(\"Accuracy: {0:.2%}\".format(result[1]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 87.10%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Igq8Qm8GeCzG",
        "colab_type": "text"
      },
      "source": [
        "## Retrive the output of each layer in keras for a given single test sample from the trained model you built"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dUDSg7VeCzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tskt_1npeCzP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "87f0d3d4-c4e7-4b1a-de0d-7784d6eb9d36"
      },
      "source": [
        "#Define function to get output of all the layers in the model for specific test input\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    sess.run(tf.tables_initializer())\n",
        "\n",
        "    def getLayerOutput(layer):\n",
        "        get_Layer_Output = k.function([model.layers[0].input], [layer.output])\n",
        "        return get_Layer_Output([x_test[0:1,]])[0]\n",
        "    \n",
        "    layer_output = []\n",
        "    \n",
        "    for layer in model.layers:\n",
        "        layer_output.append(getLayerOutput(layer))\n",
        "\n",
        "print(layer_output)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[array([[[ 0.0041155 , -0.04370933,  0.01085538, ...,  0.02347941,\n",
            "         -0.01528121, -0.04100442],\n",
            "        [ 0.0041155 , -0.04370933,  0.01085538, ...,  0.02347941,\n",
            "         -0.01528121, -0.04100442],\n",
            "        [ 0.0041155 , -0.04370933,  0.01085538, ...,  0.02347941,\n",
            "         -0.01528121, -0.04100442],\n",
            "        ...,\n",
            "        [ 0.04258528,  0.03693824, -0.02728037, ..., -0.03450607,\n",
            "          0.02184614,  0.02130951],\n",
            "        [-0.02791059, -0.01948614, -0.03185003, ..., -0.03451742,\n",
            "          0.01664151, -0.03993685],\n",
            "        [-0.02878357, -0.03301308, -0.01381617, ...,  0.01601266,\n",
            "          0.01202636,  0.03784463]]], dtype=float32), array([[[ 0.00486718, -0.00203985, -0.00140249, ...,  0.00281778,\n",
            "         -0.00370962, -0.00099983],\n",
            "        [ 0.00765251, -0.0043822 , -0.00185332, ...,  0.00443793,\n",
            "         -0.00594004, -0.00244151],\n",
            "        [ 0.00914937, -0.0067409 , -0.00180035, ...,  0.00535144,\n",
            "         -0.00735939, -0.00391256],\n",
            "        ...,\n",
            "        [-0.00976832,  0.00027523,  0.00278522, ..., -0.00364425,\n",
            "          0.00289563,  0.00205749],\n",
            "        [-0.0089741 ,  0.00143643,  0.00037401, ..., -0.00136078,\n",
            "          0.00743207,  0.0028485 ],\n",
            "        [-0.00260326,  0.00127924, -0.00212376, ..., -0.00215453,\n",
            "          0.00725914,  0.0080314 ]]], dtype=float32), array([[[-0.00032545, -0.0003693 , -0.00096983, ..., -0.00142934,\n",
            "         -0.0005567 ,  0.00119426],\n",
            "        [-0.00107241, -0.00074781, -0.00225401, ..., -0.00329013,\n",
            "         -0.00126665,  0.00268792],\n",
            "        [-0.00215548, -0.0009654 , -0.00354357, ..., -0.00509788,\n",
            "         -0.00195908,  0.00403407],\n",
            "        ...,\n",
            "        [ 0.00080943,  0.00174695, -0.00021325, ...,  0.00236173,\n",
            "          0.00429004, -0.00336745],\n",
            "        [ 0.00163181,  0.00281414,  0.00076217, ...,  0.00363725,\n",
            "          0.0036981 , -0.00439277],\n",
            "        [ 0.00196767,  0.00349656,  0.00135669, ...,  0.00359932,\n",
            "          0.00220501, -0.00449431]]], dtype=float32), array([[ 0.00103098, -0.00036572, -0.00289478, -0.00113951]],\n",
            "      dtype=float32), array([[0.4999851]], dtype=float32)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AqOnLa2eCzH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "20d508b2-5e19-4cce-85fd-bafda666d300"
      },
      "source": [
        "# Getting a specific output layer\n",
        "layer_output[2]\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.00032545, -0.0003693 , -0.00096983, ..., -0.00142934,\n",
              "         -0.0005567 ,  0.00119426],\n",
              "        [-0.00107241, -0.00074781, -0.00225401, ..., -0.00329013,\n",
              "         -0.00126665,  0.00268792],\n",
              "        [-0.00215548, -0.0009654 , -0.00354357, ..., -0.00509788,\n",
              "         -0.00195908,  0.00403407],\n",
              "        ...,\n",
              "        [ 0.00080943,  0.00174695, -0.00021325, ...,  0.00236173,\n",
              "          0.00429004, -0.00336745],\n",
              "        [ 0.00163181,  0.00281414,  0.00076217, ...,  0.00363725,\n",
              "          0.0036981 , -0.00439277],\n",
              "        [ 0.00196767,  0.00349656,  0.00135669, ...,  0.00359932,\n",
              "          0.00220501, -0.00449431]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}