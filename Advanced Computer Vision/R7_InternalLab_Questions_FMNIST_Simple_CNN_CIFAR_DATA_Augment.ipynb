{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"MyfMmMnPJjvn","colab_type":"text"},"source":["## Train a simple convnet on the Fashion MNIST dataset"]},{"cell_type":"markdown","metadata":{"id":"zjcGOJhcJjvp","colab_type":"text"},"source":["In this, we will see how to deal with image data and train a convnet for image classification task."]},{"cell_type":"markdown","metadata":{"id":"jR0Pl2XjJjvq","colab_type":"text"},"source":["### Load the  `fashion_mnist`  dataset\n","\n","** Use keras.datasets to load the dataset **"]},{"cell_type":"code","metadata":{"id":"Qr75v_UYJjvs","colab_type":"code","colab":{}},"source":["from keras.datasets import fashion_mnist\n","(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hTI42-0qJjvw","colab_type":"text"},"source":["### Find no.of samples are there in training and test datasets"]},{"cell_type":"code","metadata":{"id":"g2sf67VoJjvx","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zewyDcBlJjv1","colab_type":"code","colab":{}},"source":["\"\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WytT2eRnJjv4","colab_type":"text"},"source":["### Find dimensions of an image in the dataset"]},{"cell_type":"code","metadata":{"id":"XycQGBSGJjv5","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5jtdZ7RqJjv8","colab_type":"text"},"source":["### Convert train and test labels to one hot vectors\n","\n","** check `keras.utils.to_categorical()` **"]},{"cell_type":"code","metadata":{"id":"sAD3q5I6Jjv9","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mgHSCXy3JjwA","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xO5BRBzBJjwD","colab_type":"text"},"source":["### Normalize both the train and test image data from 0-255 to 0-1"]},{"cell_type":"code","metadata":{"id":"3fUQpMHxJjwE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Okwo_SB5JjwI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"da5-DwgrJjwM","colab_type":"text"},"source":["### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"]},{"cell_type":"code","metadata":{"id":"LPGVQ-JJJjwN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OFRRTJq8JjwQ","colab_type":"text"},"source":["### Import the necessary layers from keras to build the model"]},{"cell_type":"code","metadata":{"id":"dWTZYnKSJjwR","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C18AoS7eJjwU","colab_type":"text"},"source":["### Build a model \n","\n","** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"]},{"cell_type":"code","metadata":{"id":"DORCLgSwJjwV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ju69vKdIJjwX","colab_type":"text"},"source":["### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"]},{"cell_type":"code","metadata":{"id":"L2hAP94vJjwY","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lGTA3bfEJjwa","colab_type":"text"},"source":["### Now, to the above model, lets add Data Augmentation "]},{"cell_type":"markdown","metadata":{"id":"F6gX8n5SJjwb","colab_type":"text"},"source":["### Import the ImageDataGenrator from keras and fit the training images"]},{"cell_type":"code","metadata":{"id":"Cbz4uHBuJjwc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pl-8dOo7Jjwf","colab_type":"text"},"source":["#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"DpI1_McYJjwg","colab_type":"code","outputId":"6722631e-c925-448c-c780-93a3100249bc","colab":{}},"source":["from matplotlib import pyplot as plt\n","gen = datagen.flow(x_train[0:1], batch_size=1)\n","for i in range(1, 6):\n","    plt.subplot(1,5,i)\n","    plt.axis(\"off\")\n","    plt.imshow(gen.next().squeeze(), cmap='gray')\n","    plt.plot()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAABcCAYAAAB+6068AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAFaNJREFUeJztnWmsnGX5h6/SClZUUNytshOKaysu\nqFilILYsBSFQDSoW/SA1YIIxcflgwERATTTGL7agRiAGAuLGokGBGJaWRa0iqKitVKuighvgdv4f\n/rnO88w983ZmTuecM33PfX2ZzvQ97/K82+9en3kTExMkSZIkOz+7zPYOJEmSJKMhH+hJkiQtIR/o\nSZIkLSEf6EmSJC0hH+hJkiQtIR/oSZIkLSEf6EmSJC0hH+hJkiQtIR/oSZIkLWHBTG5s3rx5Y1uW\nOm/ePADmz5/f9X//+c9/ev7NggULev7/xMTEvCG2O3ZjEsfgv//9LwB77LFH17JLly4F4Hvf+952\n17mzj8l0MMyYQI5LL3JMOkmFniRJ0hJmVKHPJCru2KvmSU96EgCvfe1rAfjHP/4BwKOPPgrAhg0b\n+q5zl13+/z2oMn/iE58IwP/+97+R7PtME49LRqHMDz300FHsYpIkA5AKPUmSpCW0VqGrNlWZBxxw\nAADvete7AHjkkUcA2G233QB4whOeAMBRRx0FwPr16yfX9fvf/x4oat91HnfccQC8/OUvB+CWW26Z\njkOZduJxSVTmqnLYeZT5oJbatdde2/PvjCc0xVF6/Y20uZNp07gms0sq9CRJkpbQWoWuslJ1HnHE\nEQAceeSRADzwwAMA3HPPPQD8/Oc/B2DJkiUAXHjhhZPruuOOOwDYtGkTAD/96U87tuU6VP87C2bp\nyOMf/3igqNZbb70VGNxfDt3KPG5jphnUUmuKpURlHuMNtSqPy/bKmNrZ2XXXXQH417/+BZTx/MUv\nfjFr+9QGRmXdpUJPkiRpCa1V6CoI0c+9zz77AEU9qbTe/OY3A7Bx40agU3GYxXLYYYd1LPvvf/8b\ngFe84hUA7LfffqM9iGki+j9Vr294wxuAMlaqWI/7uc99buM6m5T5bbfdNqrdnhKDWmr9YilNcZSa\nmO30z3/+c5SHMq00KcR4rcT7Ss4//3wAbrrpJqA7JjGXmEr8JSryqVp3qdCTJElaQusUelQUKi0V\n5N/+9jcAdt99dwAOOuggoCg0/ce14lRx3XXXXUBR77559TFfd911QFHw40JTRasq85nPfGbH746N\nv6uyr7zyysllTjrpJGB8lbkMa6ldf/31QHcspSmOonVWr9tsJ2MQoyZaHU3ndxiiQuyXxbJu3Tqg\njJOWjjGJNiv0fhlSjllT/AW6YzDGr3bUukuFniRJ0hJap9Aj5513HgDPfvazO37XV+pb1Oi9WQ4L\nFy6cXNa35uGHHw7Aq1/9aqC8Zf3/5z3veaM/gB3At3+PXjMAvP71r+/4XWtGf/GiRYuAYoH85Cc/\nmVz2hz/8IQBnnHEGMH7KfKqWmp8xltIvjlL/jbGHxx57bKTH9KpXvQroHuN4DXvsg2y/SYnH725T\nS3bPPfcEilqNsYjacjFjaGfLXY/7O2iGVL/4C3THYD7wgQ8AO27dpUJPkiRpCTu9Qu+Xv/mXv/wF\nKAo9Vog2KUt9rPU6Yw6yKt9t1GptHNCnq0L68Ic/DBQVql9Y9fmUpzwFgGOOOaZjPb/73e+AzuNz\n/M455xwA3vKWt4z+AAYkXgO9GNRS0+ceYyn94igAa9euBUq208knnzzsoQzEd77zHaAowac+9akA\n/PnPfwbK9RktyF409e8R/cOOm+fd+yhuc+vWrQC89a1vnVyH19/Ooswl1jAMmiH1xz/+EeiOv9TE\nWIyWopbPRRddBMDnPve54fZ5qKWTJEmSsSUf6EmSJC1h3kyaQbPZjN6CB81hTUbdCJpJBjAMfAL8\n6U9/AopJZfDJwJrrPPfccwE4//zzZ6VB/4oVK4ASpBEDeLpW5De/+Q0Ap5xyClDMPvHa6FXkoCmo\nif3www8D8I1vfKPnvs32pAW6Dg455BCg2fVm+pgBLs1t3RbRDK9dFs94xjOAkr5qamcTw05w8cAD\nD0zU25Zjjz224/uPf/zjxnXEVgzuv64mr5G7774bgN/+9rdAcUE6brrndDl5L3z2s58FSjojFFef\n91Y/ZvtaicR2B6ZsnnjiiUC5j/w09dUgtu65XkVZurIcmze96U1AeaZYzJcTXCRJkswxdvqgaCQW\nXag4nvOc5wAllctPFZrq1NTD+m3qMqp5VY6pjQZH6kDQTGLq2LJly4Bu9enbPiqH008/HShBRVWo\nf++YqL7r1gZr1qwBipL9yEc+AsAXvvAFAN75zneO6OhGg9ZVDBhawOExao2pSPsFxGu1PN3pqwbf\nn/zkJ3ds+2tf+xpQrv1PfOITQO+AWlPxkemnERWi94vbdNxUr15rUZVCCQ6+4x3v6Fi3+9uUXjsu\n+CwYNvXVMYmBdegOrpsKGa28YUmFniRJ0hJa40P3Lf+4xz0OKG9VlcenP/1poPjKfVv66ZtRxalS\nq9fpp29kFZPbPvDAAyd3Z4j93uExiQUPplWpgPTtReUgWhwej35k1Zdj1Cst02PXF6i1IosXLwam\n1y/aawq9aKHpE3bZaMXoK44xlH7xk3oSEMfZbTapXtm4ceNQPvQ777xzAkqaovtu6qCW2kMPPdSx\n7553gKuuugqAs88+u2Pdr3zlKwH41re+BcBf//pXoNtqc4y1aLzmvW9U2V/84hcn1+29aLGMqXqO\ndWxdMC4+9FhYZGpzndJcLxdTXz2uGIeB7liM27DdRmwtkT70JEmSOUZrfOhN7T2N+OsDVGVHX7vK\n3d9VqdCtTP3uG1df+t///negO5tklPQqotEP98tf/hIoatQovBZFzGJRbW7btg0omQsqO4/z6U9/\netc2XcZj16eqwnD8Nm/ePMzhTYle2Tie11NPPRWAZz3rWUA5z+6357AphtIvfrLXXntNblOf9Utf\n+tKOZUeF29SS8phU7Kpmj12rqW4BYNHYa17zGqCcL8cwWiQx1hQtGZf3mL0+zZyC4i8W1adTODpx\nymxPsj5IgRqUMWnKlPL+976KcRjojsV47f7oRz/qWMewUzmmQk+SJGkJrVHoTS1Er7nmGqDkZvtW\nVZ369vT/fVPWfmbVpsvG1pYqp5ko/e+lRv335z//eaCU/OvTVampEFSfTrvncvqN9cWq9GJeO5Tx\nViWqDvXnRj/9dOK+9MrzHdRCa4qhuLzXQIyf1DEDs5zMMpmuRmXuo2Nt1sv+++8PlGP2Wq/HxWvA\nc9ykzL2PPI8u73kWlXmMJ0VrEMo9ZyMqm5n53UkyZot+8USP0cyffplSjk0cW2iuZdHis6bF1hqD\nkgo9SZKkJYylQldx9ZqIN/qvRUXxmc98Big+Qt+eviV9M8YItApNNVO/TW1pqV/rda97Xcc+qNKm\n03ceqfOfY+Xg5ZdfDhQfpagwXN5j1Y+qUq8zN6AcZ6269Y3vvffeAPzhD38AijLzPMXmT4PQdP77\nnfteDGqhNcVQ+sVPakvpxS9+MdCtYkeFk5F7nWl1qNB/9atfAeX86e+2BgPKOHgtaF3GdXmcUbUa\nY9Bvb9wojofjDMXys+GZbWXF6l2toXHFZ4IWUmx+9rSnPQ0o95X3k/dXbSl5HrxfbIDnvRmtvdWr\nVw+0j6nQkyRJWsJYKfQdqRhTNRvFj/4tfVOqFt+yKrWoDurMjlWrVgEli8Q8X/1fvm2nokanA9ur\n/vrXvwaKD1014P6r3Jpyij0uVYOTWkBRia5LhadaUelN5VwO+zee+7p3yrAWmsvFGEq/+Inrg6JW\n7Z3T1NdmqsSsGa9ZrSXHPl7LtZWhRWWV8KWXXgoUde/51GduPro4DlGlxhoN7416GfnQhz7UsS19\n0k5SPtvEugavEZ8tqulBM6ZiPAaaYzJue6rW3ng8gZIkSZIdZiwUesw4iOivg6IqVZN+VxXpp/LT\nN55vQHNgzZO1+bzbUHnccMMNk9tUmbtN1b7bqHORZ5NY2WZfDTtNqoTq6fWgZKqI6sqx0AdYd6B0\nGXNtY08P9+G+++4DSgbGMHhO+p1zKyHrfOthLbSmGEq/+EmtoFTCjvuoeclLXgKUvG6PwbE160Ul\nGPPWoYzdl770pY7PF7zgBUC5hjzemI0R86ZjLyStlBqXtc7BqQz1MYv56LNNzCSLNQ2DZkx5Ppri\nMfVvTTUtw044nwo9SZKkJYyFQm9S5j/4wQ+AMi1TvaxvRf1w0e/qckb89R2a62oU/j3veQ8AZ555\nJlCUycte9rLJdenbi72joxqdrUq3fhVu+v6sIHXsosJQUeg7V2moch1DgKuvvhooqlmV79jce++9\nwNRy8+N573fOVY+98q09zyrtaJnpK1Z1xT4dL3rRizqWU1U6JrW147VTj9MoWblyJVB6otx4440d\n++S+x97m7juUjKz3vve9QFGPxonE8XActdI87qZ4kee77sxpTvXxxx8PlOuuX7/42aKprsH8fseg\nX8aUFlSMx9TL9qtpGdbaS4WeJEnSEsaq26JvIyf0Vf3VCj6+0XrlvUJRmWarqChUkieccAJQ3pqq\nm09+8pNA59tZRehbM2Z0qID0z69cuXJGu8VF33lEpaYP8IILLgDKmDmmKpPod/Z477///sl1GlfQ\nenHbVp+KY7Zq1aqBx2Tz5s0dM/MMes5rtMzMDTar441vfCNQLLPoUzfbo1/cRJVZq19/87rop9SH\nnbFo8eLFE/UxmWPvedMKcV/9va6p8DyZqSGXXXYZAO9///uBMg7Lly8Hyng4ubH+fK0kPz039bV4\n8cUXA6Vy8lOf+lTHtuMkyuPSbTFitsqWLVuAosx9hjRlTGndeH5g8JoWs8UWLlyY3RaTJEnmEjOq\n0BcsWLDdjekbNG/a6HxdgRl7hKiKVGT6E+0Gp09KBeZyZnyoOFTosZKu3uaDDz4IFNWpKvG7n6tX\nr55VhRHnAFU52PNarrjiCqD4oP10TFX+sXIUSh8O1+l4OUaqF8do+fLlA4/Jpk2bJqCc90HPuWob\nhrfMYuzEzxg38Xudfy6xJ38//+eWLVuGUujxWnH+SXuce543bNgAFJXcq4LZHvpaOWYUxdx589BV\n6lokxjdUlip6r71qbgDe9ra3AXDJJZcAZVxi3EulPgqF7rlwf5qqjutjkFjX0NSZ0uvN8+01EbPe\nfJ7VaPE4nt57Zrf4u+tetGhRKvQkSZK5xIxmubz97W/f7v/rc9RX6xuvzleN+bH6mMzQsGrOnFeV\nmG8839QqSWfUUZnrW6yr8lT3blu1pm/dT1XPbKPiiNbX7bffDhRfoL6+qBIOPvhgoPheVSIf+9jH\nJtdlrMH+zapoFYUqZdCZ3mtiL4xBz3mtRFWecSadr371q0C3ZaZCjec2WmOxGrNWd6o/97OeKWg6\ncN7JpUuXduzrt7/97Y7l6o6QXv/2hTGTyev/6KOPBsr94fL+v59eK1q6jp/XTD1jUax2tAtltGCG\n7f29Pbz2h6k6Xrt2LdBc3+D42reoqabF5XwGWdOiKofBa1qaMgCbSIWeJEnSEmZUoftma0JFpmLU\nL2tUH4pyUkGY86mijpVrcbbymP+pIvd3lUav3G5/U3WqCP0bq+6WLVu23eOcbjyW2PtDtaK/s87Q\ngKI44gwz+lXttw5FHatCPA8qDPehrt4cFM+N533Qc96rV8aglpnXntfcoHGTOg899oY3q2O6Medf\nrBx1JquaWCXs9e94OfZe2943jq3j5fmNWRm96g6aetpEpT7KGZ6aqs9j9TEUtfzud78baK5v8P7X\ngm2qaYmZU15Dda+aQWtaBp1FaXK9Qy2dJEmSjC0zmuWyZMmS7W5s3bp1QHmj6Y+rO75Ff7afKg/9\nlyoP39QxV1vFETvTqSjrnhQxa8R1qEZUNfYwHtc82hi9t1+6lpPKw5xtlWb0OwM8//nPB4r/2owT\nx1nlZnXjMGNy8803T0A574Oe8/o8xZnXo2UW+32r5OLMVyqn6Fv3Gq1n5vF63XfffQG48MILt3uc\nX/7yl3coy2Uq2C8lWqLGVcTxMUMjdtEUx89j9//r3PdhGeX9Y+dRs55i9TGU6yZWgEa8xv3bQTOn\nYndJaK5psY7Da9ttLF26NLNckiRJ5hL5QE+SJGkJY1X6/8EPfhCANWvWAHDWWWcBpRwZSpqVJq9m\nTGzgZCFEnMhAdDN4/Fu3bgVGE9Acd5eLkxpoZmsaGoQ06KvbwdQ0xxyKS6spyBanvxtmTL773e9O\nwODnOk5aUf9fP1dbnOAkBqFiIFz8uzptUfPYVE7T2ZoYtvR/lNeKbQNk0aJFQHE16mKKKYc2K3Nc\n4qfsSIOyUdw/BlotnvOaaWonAaVwqKlgLRarxfujKRU2pvZCc7DdgL+uPF1Xxx9/fLpckiRJ5hJj\npdAHwdSfj3/840BRcb5VfXsefvjhQFEeTsfmG7FuNDVqZluhx8lrxQIHA10x+KMaqNseQFEuqgfo\nbvLv96ZpxKYyJoOea9V4rdAHtcgcI5XpoAFwt23QDUraZ92EaXvMpkIXlbrHGdssOC4qSC0yA+hi\nQFC1uiMMMy5N7URsI+J+x4B6PM56We+LWLAW24jEVgAGXOOE5N43dZFT3L4WkctEC3DZsmWp0JMk\nSeYSM6rQ58+fP9DGpjJRhIpBP/D3v//9odcxKmZLofvWj8U8ljRbOBHVq4o3NjSzKEdFUvuRVeYq\nsn5tD0Y5JvFc61vXGoOZtcimyjgo9IgTl8R2C1o0Ylm81p4NuH72s591rTNONdePYcZlzZo1PcfE\noh8tM+8J1XPdJsJjjAVr8TmkBRuLrvqlxMaU3pqmGI0+di3A9evXp0JPkiSZS+x0PvSdgZlW6LEY\nRl74whcC8M1vfhPojuxbIu5UZmI5vyrcMv8aI/mDTv4823GFcWQcFbp85Stf6fge2xpYPGW7C3H6\nwB1R6sOMy7HHHrvdMfnoRz8KdBeC1U2wtPAsZOtXuKa/2/uiXwZVLHKs6VekWC2XCj1JkmQukQp9\nGpgJNVr74+I5NP/VJls2GRKj80bh/dy2bVvH30dlUU+QYeOpQX3TqdC7GWeFLmeccQZQMnje9773\ndfz/17/+daBcU6JSr1G191Pqw4xLv3YiK1asAEptiznl22snop+9qc4h3g/9MqiaMr+GIRV6kiTJ\nHCMV+jQwE2q09sfFrBXVUWyPa66wvj8bKamy/R4j7ioMJ1Koia1bm0iF3s3OoNAH5bTTTuv4Xiv2\nqNajfz0q9um4VlTqVp1b0wDdlchWVDfVOXi/DWul7gip0JMkSeYYM6rQkyRJkukjFXqSJElLyAd6\nkiRJS8gHepIkSUvIB3qSJElLyAd6kiRJS8gHepIkSUvIB3qSJElLyAd6kiRJS8gHepIkSUvIB3qS\nJElLyAd6kiRJS8gHepIkSUvIB3qSJElLyAd6kiRJS8gHepIkSUvIB3qSJElLyAd6kiRJS8gHepIk\nSUvIB3qSJElLyAd6kiRJS8gHepIkSUvIB3qSJElLyAd6kiRJS/g/5hM1fR9FmUsAAAAASUVORK5C\nYII=\n","text/plain":["<matplotlib.figure.Figure at 0x7f5491602650>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"dmPl5yE8Jjwm","colab_type":"text"},"source":["### Run the above model using fit_generator()"]},{"cell_type":"code","metadata":{"id":"44ZnDdJYJjwn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MwQQW5iOJjwq","colab_type":"text"},"source":["###  Report the final train and validation accuracy"]},{"cell_type":"code","metadata":{"id":"c1SrtBEPJjwq","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZBwVWNQC2qZD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8KXqmUDW2rM1","colab_type":"text"},"source":["## **DATA AUGMENTATION ON CIFAR10 DATASET**"]},{"cell_type":"markdown","metadata":{"id":"8mja6OgQ3L18","colab_type":"text"},"source":["One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."]},{"cell_type":"markdown","metadata":{"id":"6HzVTPUM3WZJ","colab_type":"text"},"source":["### **Import neessary libraries for data augmentation**"]},{"cell_type":"code","metadata":{"id":"PPM558TX4KMb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W6hicLwP4SqY","colab_type":"text"},"source":["### **Load CIFAR10 dataset**"]},{"cell_type":"code","metadata":{"id":"NQ1WzrXd4WNk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9Pht1ggHuiT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3n28ccU6Hp6s","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JN3vYYhK4W0u","colab_type":"text"},"source":["### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"]},{"cell_type":"code","metadata":{"id":"JJbekTKi4cmM","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e-SLtUhC4dK2","colab_type":"text"},"source":["### **Prepare/fit the generator.**"]},{"cell_type":"code","metadata":{"id":"CSw8Bv2_4hb0","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gYyF-P8O4jQ8","colab_type":"text"},"source":["### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"]},{"cell_type":"code","metadata":{"id":"mXug4z234mwQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}