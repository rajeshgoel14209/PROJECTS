{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "v1.1_Hackathon_GL_GreatStone_Rating_Neural [Hyperparameters Tuning].ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsw1Lk-cSNar",
        "colab_type": "code",
        "outputId": "e6afd82e-2a28-4de4-b136-b229910053f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbCsFzkIUL61",
        "colab_type": "code",
        "outputId": "baadfd6f-8c99-4426-e425-d672ea96afcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        }
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import seaborn as sns\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "! pip install plotly_express\n",
        "import plotly_express as px"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting plotly_express\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/d6/8a2906f51e073a4be80cab35cfa10e7a34853e60f3ed5304ac470852a08d/plotly_express-0.4.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.10.2)\n",
            "Requirement already satisfied: scipy>=0.18 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.4.1)\n",
            "Requirement already satisfied: plotly>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (4.4.1)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (0.5.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.18.4)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from plotly_express) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->plotly_express) (1.12.0)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.1.0->plotly_express) (1.3.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly_express) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.20.0->plotly_express) (2.8.1)\n",
            "Installing collected packages: plotly-express\n",
            "Successfully installed plotly-express-0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TvLJ9NrUL4B",
        "colab_type": "code",
        "outputId": "9c18a293-6229-476b-8934-6a74a24137e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import pytz\n",
        "from datetime import datetime\n",
        "# assuming now contains a timezone aware datetime\n",
        "now = datetime.now()\n",
        "tz = pytz.timezone('Asia/Kolkata')\n",
        "your_now = now.astimezone(tz)\n",
        "print (your_now)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-15 06:56:37.095312+05:30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pGxylPwsMK-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureEngineering/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nf_AgtERkPr",
        "colab_type": "code",
        "outputId": "5d4dc581-30f2-4794-dc94-bd2d5a98b2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bond_ratings.csv  finalDf_pca.csv\tfund_specs.csv\t     return_3year.csv\n",
            "data.csv\t  fund_allocations.csv\tother_specs.csv      return_5year.csv\n",
            "data_joined.csv   fund_config.csv\tprimary_keys_df.csv\n",
            "data_tst_ids.csv  fund_ratios.csv\treturn_10year.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw5wvq6_RY7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## copying the files to feature selection folder\n",
        "!cp data.csv  '/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/'\n",
        "!cp data_joined.csv  '/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Rj5a9vNR7i3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYrdgxMZRbOE",
        "colab_type": "code",
        "outputId": "383ef531-c06b-4c92-af79-908c3901ffdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Activaation Size.jpg'\t\t  df_ns_df_sorted_chi2.csv\n",
            " best_columns.csv\t\t  df_ns_df_sorted_FI.csv\n",
            " convolutional_architecture.jpg   Feature-Selection-Methods.png\n",
            " data.csv\t\t\t  finalDf_pca.csv\n",
            " data_joined.csv\t\t  sample_submission.csv\n",
            " data_tst_ids.csv\t\t 'Trainable Parameters.jpg'\n",
            " df_ns_df_sorted_annova.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP6o8JiEXs8Q",
        "colab_type": "code",
        "outputId": "40e33d48-7871-40a7-99a1-80c4b4fa54e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "data = pd.read_csv(\"/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/data.csv\")\n",
        "data_joined = pd.read_csv(\"/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/data_joined.csv\")\n",
        "best_columns = pd.read_csv(\"/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/best_columns.csv\")\n",
        "sample_submission = pd.read_csv(\"/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/sample_submission.csv\")\n",
        "data_tst_ids = pd.read_csv(\"/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/data_tst_ids.csv\")\n",
        "finalDf_pca = pd.read_csv(\"/gdrive/My Drive/Hackathon/GREATLEARNING-APRIL/FeatureSelection/finalDf_pca.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning:\n",
            "\n",
            "Columns (7,9,10,18,57,80) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baXmDHErupBT",
        "colab_type": "code",
        "outputId": "35f625b5-71d0-4717-f4e2-160f5ccacc03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        }
      },
      "source": [
        "col_int = data.drop(columns=['greatstone_rating'],axis=1).select_dtypes(exclude=('category','object')).columns\n",
        "col_id = ['tag','id','fund_id']\n",
        "col_tgt = ['greatstone_rating']\n",
        "col_cat = data.drop(columns=['greatstone_rating'],axis=1).select_dtypes(include=('category','object')).columns\n",
        "print(len(col_int)+len(col_id)+len(col_tgt)+len(col_cat))\n",
        "print('col_int :- ',len(col_int),'| col_cat :-',len(col_cat),'| col_id :-',len(col_id),'| col_tgt :-',len(col_tgt))\n",
        "print(col_cat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "958\n",
            "col_int :-  954 | col_cat :- 0 | col_id :- 3 | col_tgt :- 1\n",
            "Index([], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QH-aIJ-UL0A",
        "colab_type": "code",
        "outputId": "e78bd06d-cbb9-474f-bd4e-a8133e5124a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# multi-class classification with Keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import EarlyStopping,  ModelCheckpoint\n",
        "from keras.preprocessing import sequence\n",
        "# fix random seed for reproducibility\n",
        "numpy.random.seed(7)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSqetCEMUab9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dependencies\n",
        "# Use scikit-learn to grid search the batch size and epochs\n",
        "import numpy\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "# Function to create model, required for KerasClassifier\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "##########################################  SPLITTING THE DATA INTO TRAINING AND TESTING ###############################################\n",
        "\n",
        "data_train = data[~data.greatstone_rating.isnull()]\n",
        "data_tst = data[data.greatstone_rating.isnull()]\n",
        "# split into input (X) and output (Y) variables\n",
        "X_0 = data_train[col_int]  \n",
        "y_0 = data_train[col_tgt]\n",
        "\n",
        "\n",
        "ohe = OneHotEncoder()\n",
        "y_train_0 = ohe.fit_transform(y_0).toarray()\n",
        "num_classes = len(y_train_0[0])\n",
        "\n",
        "\n",
        "mm_scaler = preprocessing.MinMaxScaler()    #  MinMaxScaler() #StandardScaler\n",
        "X_train_minmax_0 = mm_scaler.fit_transform(X_0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def create_model(neurons,optimizer,learn_rate, momentum ,init_mode,activation,dropout_rate):\n",
        "    \n",
        "    \n",
        "    #Initialize model, reshape & normalize data\n",
        "    tf.keras.backend.clear_session()\n",
        "    #tf.keras.Sequential(layers=None, name=None)\n",
        "    # Neural network\n",
        "    print(\"optimizer :- \",optimizer,\"\\n\",\"learn_rate :- \",learn_rate,\"\\n\",\"momentum :- \",momentum,\"\\n\",\"init_mode :- \",init_mode,\"\\n\",\"activation :- \",activation,\"\\n\",\"dropout_rate :- \",dropout_rate,\"\\n\",\"weight_constraint :- \",weight_constraint,\"\\n\")\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(neurons, input_dim=X_train_minmax_0.shape[1], kernel_initializer='uniform', activation=activation, name='Input_layer'))\n",
        "    #model1.add(Dense(output_dim=128, init='he_normal', bias=True))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    #Hidden layers 1\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation=activation, name='Layer_1'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    #Dropout layer\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    #Hidden layers 2\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation=activation, name='Layer_2'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    #Dropout layer\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    #Hidden layers 3\n",
        "    model.add(tf.keras.layers.Dense(neurons, activation=activation, name='Layer_3'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    #Hidden layers 4\n",
        "    model.add(tf.keras.layers.Dense(50, activation=activation, name='Layer_4'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    #Dropout layer\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    #Hidden layers 5\n",
        "    model.add(tf.keras.layers.Dense(25, activation=activation, name='Layer_5'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    #Dropout layer\n",
        "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer='uniform', name='Output_layer'))\n",
        "\n",
        "\n",
        "    #Create optimizer with non-default learning rate\n",
        "    sgd_optimizer = tf.keras.optimizers.SGD(lr=learn_rate, decay=0.001 , momentum = momentum, nesterov=True)           # 'adam'\n",
        "    rms = RMSprop(lr=learn_rate, rho=0.9, epsilon=None, decay=0.0)\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=optimizer, metrics=['accuracy'])            # model.compile(loss='mean_absolute_error', optimizer='adam' , metrics=['mae'])\n",
        "    \n",
        "    print(\"optimizer :- \",optimizer,\"\\n\",\"learn_rate :- \",learn_rate,\"\\n\",\"momentum :- \",momentum,\"\\n\",\"init_mode :- \",init_mode,\"\\n\",\"activation :- \",activation,\"\\n\",\"dropout_rate :- \",dropout_rate,\"\\n\",\"weight_constraint :- \",weight_constraint,\"\\n\")   \n",
        "    \n",
        "    return model\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZEcIKqUUaZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KerasClassifier(build_fn=create_model, verbose=0, epochs=10, batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZDlTNzFWiX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the grid search parameters\n",
        "\n",
        "batch_size = [32,64 ]                     #, 20, 40, 60, 80, 100]\n",
        "epochs = [2]                              #,10, 50, 100]\n",
        "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam','sgd_optimizer']            # , 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam',sgd_optimizer]\n",
        "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]                      # , 0.01, 0.1, 0.2, 0.3]\n",
        "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]                          # , 0.2, 0.4, 0.6, 0.8, 0.9]\n",
        "neurons = [50,100,200,400,800,450]\n",
        "init_mode = ['uniform', 'he_normal', 'glorot_normal', 'glorot_uniform', 'he_uniform']      #, 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_uniform']\n",
        "activation = ['relu', 'linear','softmax', 'softplus', 'softsign',  'tanh', 'sigmoid', 'hard_sigmoid']           # ,'softmax', 'softplus', 'softsign',  'tanh', 'sigmoid', 'hard_sigmoid']\n",
        "dropout_rate = [0.4, 0.3, 0.1, 0.5, 0.6, 0.7, 0.8]                      # , 0.1, 0.2, 0.3, 0.1, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "weight_constraint = [1]                   #, 2, 3, 4, 5]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7asKWlJWldu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = dict(batch_size=batch_size, epochs=epochs,optimizer=optimizer,learn_rate=learn_rate, momentum=momentum,neurons=neurons\n",
        "                  ,init_mode=init_mode,activation=activation,dropout_rate=dropout_rate              \n",
        "                  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHJxKx9fVDj0",
        "colab_type": "code",
        "outputId": "ce7541e5-ee41-4154-d9de-fdea1dc7bd6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=10)\n",
        "\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "# assuming now contains a timezone aware datetime\n",
        "now = datetime.now()\n",
        "tz = pytz.timezone('Asia/Kolkata')\n",
        "your_now = now.astimezone(tz)\n",
        "print (\"Start Time :- \", your_now)\n",
        "\n",
        "\n",
        "grid_result = grid.fit(X_train_minmax_0,y_train_0)\n",
        "\n",
        "\n",
        "import pytz\n",
        "from datetime import datetime\n",
        "# assuming now contains a timezone aware datetime\n",
        "now = datetime.now()\n",
        "tz = pytz.timezone('Asia/Kolkata')\n",
        "your_now = now.astimezone(tz)\n",
        "print (\"End Time :- \", your_now)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Time :-  2020-05-15 06:58:31.929969+05:30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:706: UserWarning:\n",
            "\n",
            "A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOUSAc1sVD0P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Z2esaSkVD6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "678DE3igVDxC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9iUZBCvVDtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSICShYAVDqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj76ovrbULyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTgORaVjULs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}